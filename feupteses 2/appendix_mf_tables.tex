\chapter{Pymfe Meta feature tables} \label{ap1:pymfe_mf}

\begin{table}[h!]
  \centering
  \caption{Pymfe general meta features}
  \setlength{\tabcolsep}{8pt}
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{lll}
    \hline
    Family & Meta Feature & Description \\ \hline
  general & attr\_to\_inst & Compute the ratio between the number of attributes.\\
  general & cat\_to\_num & Compute the ratio between the number of \\ & & categoric and numeric features.\\
  general & freq\_class & Compute the relative frequency of each distinct class.\\
  general & inst\_to\_attr & Compute the ratio between the number of instances\\ & & and attributes.\\
  general & nr\_attr & Compute the total number of attributes.\\
  general & nr\_bin & Compute the number of binary attributes.\\
  general & nr\_cat & Compute the number of categorical attributes.\\
  general & nr\_class & Compute the number of distinct classes.\\
  general & nr\_inst & Compute the number of instances (rows) in the dataset.\\
  general & nr\_num & Compute the number of numeric features.\\
  general & num\_to\_cat & Compute the number of numerical and categorical features. \\ \hline
  \end{tabular}
  \label{tab:pymfe-general-mf}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Pymfe statistical meta features}
  \setlength{\tabcolsep}{8pt}
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{lll}
    \hline
    Family & Meta Feature & Description \\ \hline
    statistical & can\_cor & Compute canonical correlations of data.\\
    statistical & cor & Compute the absolute value of the correlation of distinct dataset\\ & & column pairs.\\
    statistical & cov & Compute the absolute value of the covariance of distinct dataset\\ & & attribute pairs.\\
    statistical & eigenvalues & Compute the eigenvalues of covariance matrix from dataset.\\
    statistical & g\_mean & Compute the geometric mean of each attribute.\\
    statistical & gravity & Compute the distance between minority and majority classes\\ & & center of mass.\\
    statistical & h\_mean & Compute the harmonic mean of each attribute.\\
    statistical & iq\_range & Compute the interquartile range (IQR) of each attribute.\\
    statistical & kurtosis & Compute the kurtosis of each attribute.\\
    statistical & lh\_trace & Compute the Lawley-Hotelling trace.\\
    statistical & mad & Compute the Median Absolute Deviation (MAD) adjusted by a\\ & & factor.\\
    statistical & max & Compute the maximum value from each attribute.\\
    statistical & mean & Compute the mean value of each attribute.\\
    statistical & median & Compute the median value from each attribute.\\
    statistical & min & Compute the minimum value from each attribute.\\
    statistical & nr\_cor\_attr & Compute the number of distinct highly correlated pair\\ & & of attributes.\\
    statistical & nr\_disc & Compute the number of canonical correlation between each\\ & & attribute and class.\\
    statistical & nr\_norm & Compute the number of attributes normally distributed based\\ & & in a given method.\\
    statistical & nr\_outliers & Compute the number of attributes with at least one outlier value.\\
    statistical & p\_trace & Compute the Pillai’s trace.\\
    statistical & range & Compute the range (max - min) of each attribute.\\
    statistical & roy\_root & Compute the Roy’s largest root.\\
    statistical & sd & Compute the standard deviation of each attribute.\\
    statistical & sd\_ratio & Compute a statistical test for homogeneity of covariances.\\
    statistical & skewness & Compute the skewness for each attribute.\\
    statistical & sparsity & Compute (possibly normalized) sparsity metric for each attribute.\\
    statistical & t\_mean & Compute the trimmed mean of each attribute.\\
    statistical & var & Compute the variance of each attribute.\\
    statistical & w\_lambda & Compute the Wilks’ Lambda value.\\\hline
  \end{tabular}
  \label{tab:pymfe-statistical-mf}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Pymfe Information-theoretic meta features}
  \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
      \begin{tabular}{lll}
        \hline
      Family & Meta Feature & Description \\
      \hline
      info-theory & attr\_conc & Compute concentration coef. of each pair of distinct attributes.\\
      info-theory & attr\_ent & Compute Shannon’s entropy for each predictive attribute.\\
      info-theory & class\_conc & Compute concentration coefficient between each attribute\\ & & and class.\\
      info-theory & class\_ent & Compute target attribute Shannon’s entropy.\\
      info-theory & eq\_num\_attr & Compute the number of attributes equivalent for a predictive\\ & & task.\\
      info-theory & joint\_ent & Compute the joint entropy between each attribute and class.\\
      info-theory & mut\_inf & Compute the mutual information between each attribute and\\ & & target.\\
      info-theory & ns\_ratio & Compute the noisiness of attributes.\\\hline
  \end{tabular}
  \label{tab:pymfe-it-mf}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Pymfe Model-based meta features}
  \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
      \begin{tabular}{lll}
        \hline
      Family & Meta Feature & Description \\
      \hline
      model-based & leaves & Compute the number of leaf nodes in the DT model.\\
      model-based & leaves\_branch & Compute the size of branches in the DT model.\\
      model-based & leaves\_corrob & Compute the leaves corroboration of the DT model.\\
      model-based & leaves\_homo & Compute the DT model Homogeneity for every leaf node.\\
      model-based & leaves\_per\_class & Compute the proportion of leaves per class in DT model.\\
      model-based & nodes & Compute the number of non-leaf nodes in DT model.\\
      model-based & nodes\_per\_attr & Compute the ratio of nodes per number of attributes in\\ & & DT model.\\
      model-based & nodes\_per\_inst & Compute the ratio of non-leaf nodes per number of \\ & & instances in DT model.\\
      model-based & nodes\_per\_level & Compute the ratio of number of nodes per tree level in\\ & & DT model.\\
      model-based & nodes\_repeated & Compute the number of repeated nodes in DT model.\\
      model-based & tree\_depth & Compute the depth of every node in the DT model.\\
      model-based & tree\_imbalance & Compute the tree imbalance for each leaf node.\\
      model-based & tree\_shape & Compute the tree shape for every leaf node.\\
      model-based & var\_importance & Compute the features importance of the DT model for\\ & & each attribute.\\\hline
  \end{tabular}
  \label{tab:pymfe-mb-mf}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Pymfe Landmarking meta features}
  \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
      \begin{tabular}{lll}
        \hline
      Family & Meta Feature & Description \\
      \hline
      landmarking & best\_node & Performance of a the best single decision tree node.\\
      landmarking & elite\_nn & Performance of Elite Nearest Neighbor.\\
      landmarking & linear\_discr & Performance of the Linear Discriminant classifier.\\
      landmarking & naive\_bayes & Performance of the Naive Bayes classifier.\\
      landmarking & one\_nn & Performance of the 1-Nearest Neighbor classifier.\\
      landmarking & random\_node & Performance of the single decision tree node\\ & & model induced by a random attribute.\\
      landmarking & worst\_node & Performance of the single decision tree node\\ & & model induced by the worst informative attribute.\\\hline
  \end{tabular}
  \label{tab:pymfe-landmarking-mf}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Pymfe Clustering meta features}
  \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
      \begin{tabular}{lll}
      \hline
      Family & Meta Feature & Description \\ \hline
      clustering & ch & Compute the Calinski and Harabasz index. \\
      clustering & int & Compute the INT index.\\
      clustering & nre & Compute the normalized relative entropy.\\
      clustering & pb & Compute the pearson correlation between \\
      & & class matching and instance distances.\\
      clustering & sc & Compute the number of clusters with\\ & & size smaller than a given size.\\
      clustering & sil & Compute the mean silhouette value.\\
      clustering & vdb & Compute the Davies and Bouldin Index.\\
      clustering & vdu & Compute the Dunn Index.\\ \hline
    \end{tabular}
    \label{tab:pymfe-clustering-mf}
  \end{table}

   \begin{table}[h!]
    \centering
    \caption{Pymfe concept meta features}
    \setlength{\tabcolsep}{8pt}
      \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{lll}
          \hline
          Family & Meta Feature & Description \\ \hline
        concept & cohesiveness & Compute the improved version of the weighted distance,\\ & & that captures how dense or sparse is the example distribution.\\
        concept & conceptvar & Compute the concept variation that estimates the variability\\ & & of class labels among examples.\\
        concept & impconceptvar & Compute the improved concept variation that estimates the\\ & & variability of class labels among examples.\\
        concept & wg\_dist & Compute the weighted distance, that captures how dense or\\ & & sparse is the example distribution.\\\hline
    \end{tabular}
    \label{tab:pymfe-concept-mf}
  \end{table}

  \begin{table}[h!]
    \centering
    \caption{Pymfe itemset meta features}
    \setlength{\tabcolsep}{8pt}
      \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{lll}
          \hline
          Family & Meta Feature & Description \\ \hline
          itemset & one\_itemset & Compute the one itemset meta feature.\\          
          itemset & two\_itemset & Compute the two itemset meta feature.\\\hline

    \end{tabular}
    \label{tab:pymfe-itemset-mf}
  \end{table}

  \begin{table}[h!]
    \centering
    \caption{Pymfe complexity meta features}
    \setlength{\tabcolsep}{8pt}
      \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{lll}
        \hline
        Family & Meta Feature & Description \\ \hline
      complexity & c & Compute the entropy of class proportions.\\
      complexity & c2 & Compute the imbalance ratio.\\
      complexity & cls\_coef & Clustering coefficient.\\
      complexity & density & Average density of the network.\\
      complexity & f1 & Maximum Fisher's discriminant ratio.\\
      complexity & f1v & Directional-vector maximum Fisher's \\ & & discriminant ratio.\\
      complexity & f2 & Volume of the overlapping region.\\
      complexity & f3 & Compute feature maximum individual \\ & & efficiency.\\
      complexity & f4 & Compute the collective feature efficiency.\\
      complexity & hubs & Hub score.\\
      complexity & l1 & Sum of error distance by linear programming.\\
      complexity & l2 & Compute the OVO subsets error rate of\\ & & linear classifier.\\
      complexity & l3 & Non-Linearity of a linear classifier.\\
      complexity & lsc & Local set average cardinality.\\
      complexity & n1 & Compute the fraction of borderline \\ & &points.\\
      complexity & n2 & Ratio of intra and extra class nearest\\ & & neighbor distance.\\
      complexity & n3 & Error rate of the nearest neighbor classifier.\\
      complexity & n4 & Compute the non-linearity of the k-NN Classifier.\\
      complexity & t1 & Fraction of hyperspheres covering data.\\
      complexity & t2 & Compute the average number of features \\ & &per dimension.\\
      complexity & t3 & Compute the average number of PCA \\ & &dimensions per points.\\
      complexity & t4 & Compute the ratio of the PCA dimension \\ & & to the original dimension.\\\hline
    \end{tabular}
    \label{tab:pymfe-complexity-mf}
  \end{table}